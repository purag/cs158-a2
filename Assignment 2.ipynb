{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class artist:\n",
    "    def __init__(self, aid = -1, name = \"\", url = \"\"):\n",
    "        self.aid = aid\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.listens = 0\n",
    "        self.user_listens = set()\n",
    "        self.tags = defaultdict(int)\n",
    "        self.weighted_tags = defaultdict(int)\n",
    "\n",
    "class tag:\n",
    "    def __init__(self, tid = 0, tag = \"\", uid = -1, aid = -1):\n",
    "        self.uid = uid\n",
    "        self.aid = aid\n",
    "        self.tag = tag\n",
    "        self.uid = uid\n",
    "        self.aid = aid\n",
    "\n",
    "class user:\n",
    "    def __init__(self, uid = -1):\n",
    "        self.uid = uid\n",
    "        self.friends = set()\n",
    "        self.artist_listens = {}\n",
    "        self.listens = 0\n",
    "        self.artist_tags = defaultdict(set)\n",
    "        self.tags = defaultdict(int)\n",
    "        self.weighted_tags = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_artists: ['url', 'pictureURL', 'id', 'name']\n",
      "data_tags: ['tagID', 'tagValue']\n",
      "data_user_artists: ['artistID', 'userID', 'weight']\n",
      "data_user_friends: ['userID', 'friendID']\n",
      "data_user_taggedartists: ['tagID', 'userID', 'month', 'artistID', 'year', 'day']\n"
     ]
    }
   ],
   "source": [
    "with open('data/artists.dat') as csvf:\n",
    "    data_artists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_artists: \" + str(data_artists[0].keys())\n",
    "\n",
    "with open('data/tags.dat') as csvf:\n",
    "    data_tags = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_tags: \" + str(data_tags[0].keys())\n",
    "\n",
    "with open('data/user_artists.dat') as csvf:\n",
    "    data_user_artists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_artists: \" + str(data_user_artists[0].keys())\n",
    "\n",
    "with open('data/user_friends.dat') as csvf:\n",
    "    data_user_friends = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_friends: \" + str(data_user_friends[0].keys())\n",
    "\n",
    "with open('data/user_taggedartists.dat') as csvf:\n",
    "    data_user_taggedartists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_taggedartists: \" + str(data_user_taggedartists[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.shuffle(data_artists)\n",
    "np.random.shuffle(data_tags)\n",
    "np.random.shuffle(data_user_artists)\n",
    "np.random.shuffle(data_user_friends)\n",
    "np.random.shuffle(data_user_taggedartists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get all the unique users\n",
    "users = {}\n",
    "# for d in data_user_artists: users[d['userID']] = user(d['userID'])\n",
    "# for d in data_user_friends: users[d['userID']] = user(d['userID'])\n",
    "# for d in data_user_taggedartists: users[d['userID']] = user(d['userID'])\n",
    "# then, get all the unique artists\n",
    "artists = {d['id']: artist(d['id'], d['name'], d['url']) for d in data_artists}\n",
    "# finally, get all the unique tags\n",
    "tags = {d['tagID']: tag(d['tagID'], d['tagValue']) for d in data_tags}\n",
    "    \n",
    "train = {\n",
    "    'set': data_user_artists[:int(len(data_user_artists) * .8)],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "test = {\n",
    "    'set': data_user_artists[int(len(data_user_artists) * .8):int(len(data_user_artists) * .88)],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "valid = {\n",
    "    'set': data_user_artists[int(len(data_user_artists) * .88):],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "\n",
    "for a in [train, test, valid]:\n",
    "    for s in a['set']:\n",
    "        uid = s['userID']\n",
    "        aid = s['artistID']\n",
    "        if uid not in users:\n",
    "            users[uid] = user(uid)\n",
    "        if uid not in a['users']:\n",
    "            a['users'][uid] = user(uid)\n",
    "        if aid not in a['artists']:\n",
    "            a['artists'][aid] = artist(aid, artists[aid].name, artists[aid].url)\n",
    "        if aid not in a['users'][uid].artist_listens:\n",
    "            a['users'][uid].artist_listens[aid] = 0\n",
    "        a['users'][uid].artist_listens[aid] = int(s['weight'])\n",
    "        a['users'][uid].listens += int(s['weight'])\n",
    "        a['artists'][aid].listens += int(s['weight'])\n",
    "        a['artists'][aid].user_listens.add(uid)\n",
    "        artists[aid].listens += int(s['weight'])\n",
    "\n",
    "# build the rest of the data now that we know which users/artists are in each set\n",
    "for d in data_user_friends:\n",
    "    for a in [train, test, valid]:\n",
    "        if d['userID'] in a['users'] and d['friendID'] in a['users']:\n",
    "            a['users'][d['userID']].friends.add(d['friendID'])\n",
    "            a['users'][d['friendID']].friends.add(d['userID'])\n",
    "for d in data_user_taggedartists:\n",
    "    for a in [train, test, valid]:\n",
    "        if d['userID'] in a['users'] and d['artistID'] in a['artists']:\n",
    "            t = tag(d['tagID'], tags[d['tagID']].tag, d['userID'], d['artistID'])\n",
    "            a['users'][d['userID']].artist_tags[d['artistID']].add(t)\n",
    "            a['users'][d['userID']].tags[d['tagID']] += 1\n",
    "            if d['artistID'] in a['users'][d['userID']].artist_listens:\n",
    "                a['users'][d['userID']].weighted_tags[d['tagID']] += a['users'][d['userID']].artist_listens[d['artistID']]\n",
    "                a['artists'][d['artistID']].weighted_tags[d['tagID']] += a['users'][d['userID']].artist_listens[d['artistID']]\n",
    "            a['artists'][d['artistID']].tags[d['tagID']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training users = 1892\n",
      "# training artists = 15382\n",
      "# testing users = 1840\n",
      "# testing artists = 3475\n",
      "# validation users = 1872\n",
      "# validation artists = 4566\n"
     ]
    }
   ],
   "source": [
    "for a, s in [(train, 'training'), (test, 'testing'), (valid, 'validation')]:\n",
    "    print \"# %s users = %d\" % (s, len(a['users'].values()))\n",
    "    print \"# %s artists = %d\" % (s, len(a['artists'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive samples in test set: 7426\n",
      "# of samples in test set: 14852\n"
     ]
    }
   ],
   "source": [
    "# grow the testing set with negative samples\n",
    "testing_set = []\n",
    "for uid, u in test['users'].iteritems():\n",
    "    testing_set.extend([(uid, aid, True) for aid in u.artist_listens.keys()])\n",
    "i = 0\n",
    "lim = len(testing_set)\n",
    "print \"# of positive samples in test set: %d\" % lim\n",
    "while i < lim:\n",
    "    uid = np.random.choice(users.keys())\n",
    "    aid = np.random.choice(artists.keys())\n",
    "    if uid in test['users'] and aid not in test['users'][uid].artist_listens:\n",
    "        testing_set.append((uid, aid, False))\n",
    "        i += 1\n",
    "print \"# of samples in test set: %d\" % len(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive samples in validation set: 11141\n",
      "# of samples in validation set: 22282\n"
     ]
    }
   ],
   "source": [
    "# grow the validation set with negative samples\n",
    "validation_set = []\n",
    "for uid, u in valid['users'].iteritems():\n",
    "    validation_set.extend([(uid, aid, True) for aid in u.artist_listens.keys()])\n",
    "i = 0\n",
    "lim = len(validation_set)\n",
    "print \"# of positive samples in validation set: %d\" % lim\n",
    "while i < lim:\n",
    "    uid = np.random.choice(users.keys())\n",
    "    aid = np.random.choice(artists.keys())\n",
    "    if uid in valid['users'] and aid not in valid['users'][uid].artist_listens:\n",
    "        validation_set.append((uid, aid, False))\n",
    "        i += 1\n",
    "print \"# of samples in validation set: %d\" % len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all the artists by most listened\n",
    "top_artists = [(a.listens, a) for aid, a in train['artists'].iteritems()]\n",
    "top_artists = sorted(top_artists, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg_artists_per_user = np.mean([len(u.artist_listens.keys()) for _, u in train['users'].iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(pred_y, prefix, acc_only = False):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    correct = 0\n",
    "    for p, y in pred_y:\n",
    "        if p and y:\n",
    "            tp += 1\n",
    "            correct += 1\n",
    "        elif p and not y:\n",
    "            fp += 1\n",
    "        elif not p and y:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "            correct += 1\n",
    "\n",
    "    # print accuracy\n",
    "    acc = correct * 1. / len(pred_y)\n",
    "    print \"%s accuracy = %f\" % (prefix, acc)\n",
    "    \n",
    "    if not acc_only:\n",
    "        # print true positive/true negative/false positive/false negative\n",
    "        print \"%s TP | FP | TN | FN = %d | %d | %d | %d\" % (prefix, tp, fp, tn, fn)\n",
    "\n",
    "        # measure precision\n",
    "        print \"%s precision = %f\" % (prefix, tp * 1. / (tp + fp))\n",
    "\n",
    "        # measure recall\n",
    "        print \"%s recall = %f\" % (prefix, tp * 1. / (tp + fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline validation accuracy = 0.570191\n",
      "baseline validation TP | FP | TN | FN = 1600 | 36 | 11105 | 9541\n",
      "baseline validation precision = 0.977995\n",
      "baseline validation recall = 0.143614\n",
      "\n",
      "baseline test accuracy = 0.570159\n",
      "baseline test TP | FP | TN | FN = 1064 | 22 | 7404 | 6362\n",
      "baseline test precision = 0.979742\n",
      "baseline test recall = 0.143280\n"
     ]
    }
   ],
   "source": [
    "# predict True if the artist is in the top 50 artists, and False otherwise\n",
    "baseline_top_artists = set([a.aid for _, a in top_artists[:50]])\n",
    "def baseline_predict(uid, aid):\n",
    "    return aid in baseline_top_artists\n",
    "\n",
    "baseline_v_pred = [(baseline_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "measure(baseline_v_pred, \"baseline validation\")\n",
    "print\n",
    "baseline_t_pred = [(baseline_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "measure(baseline_t_pred, \"baseline test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #1\n",
    "m1_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m1_predict(uid, aid):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        return len(train['users'][uid].friends & train['artists'][aid].user_listens) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 validation accuracy = 0.684274\n",
      "model 1 validation TP | FP | TN | FN = 5118 | 1012 | 10129 | 6023\n",
      "model 1 validation precision = 0.834910\n",
      "model 1 validation recall = 0.459384\n"
     ]
    }
   ],
   "source": [
    "# model 1 predictions\n",
    "m1_v_pred = [(m1_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "measure(m1_v_pred, \"model 1 validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 test accuracy = 0.682669\n",
      "model 1 test TP | FP | TN | FN = 3416 | 703 | 6723 | 4010\n",
      "model 1 test precision = 0.829328\n",
      "model 1 test recall = 0.460005\n"
     ]
    }
   ],
   "source": [
    "# testing set performance\n",
    "m1_t_pred = [(m1_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "measure(m1_t_pred, \"model 1 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #2\n",
    "m2_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m2_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 validation (jac_thresh = 0.000000) accuracy = 0.707656\n",
      "model 2 validation (jac_thresh = 0.005000) accuracy = 0.707656\n",
      "model 2 validation (jac_thresh = 0.010000) accuracy = 0.707656\n",
      "model 2 validation (jac_thresh = 0.015000) accuracy = 0.779104\n",
      "model 2 validation (jac_thresh = 0.020000) accuracy = 0.779867\n",
      "model 2 validation (jac_thresh = 0.025000) accuracy = 0.794632\n",
      "model 2 validation (jac_thresh = 0.030000) accuracy = 0.807603\n",
      "model 2 validation (jac_thresh = 0.035000) accuracy = 0.808231\n",
      "model 2 validation (jac_thresh = 0.040000) accuracy = 0.814379\n",
      "model 2 validation (jac_thresh = 0.045000) accuracy = 0.811956\n",
      "model 2 validation (jac_thresh = 0.050000) accuracy = 0.812853\n",
      "model 2 validation (jac_thresh = 0.055000) accuracy = 0.808769\n",
      "model 2 validation (jac_thresh = 0.060000) accuracy = 0.805269\n",
      "model 2 validation (jac_thresh = 0.065000) accuracy = 0.801409\n",
      "model 2 validation (jac_thresh = 0.070000) accuracy = 0.792299\n",
      "model 2 validation (jac_thresh = 0.075000) accuracy = 0.784849\n",
      "model 2 validation (jac_thresh = 0.080000) accuracy = 0.778027\n",
      "model 2 validation (jac_thresh = 0.085000) accuracy = 0.769769\n",
      "model 2 validation (jac_thresh = 0.090000) accuracy = 0.762050\n",
      "model 2 validation (jac_thresh = 0.095000) accuracy = 0.752940\n",
      "model 2 validation (jac_thresh = 0.100000) accuracy = 0.742258\n"
     ]
    }
   ],
   "source": [
    "# model 2 predictions\n",
    "for jac_thresh in np.arange(0, 0.105, 0.005):\n",
    "    m2_v_pred = [(m2_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m2_v_pred, \"model 2 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 validation (jac_thresh = 0.035000) accuracy = 0.808231\n",
      "model 2 validation (jac_thresh = 0.036000) accuracy = 0.808904\n",
      "model 2 validation (jac_thresh = 0.037000) accuracy = 0.810385\n",
      "model 2 validation (jac_thresh = 0.038000) accuracy = 0.813527\n",
      "model 2 validation (jac_thresh = 0.039000) accuracy = 0.813975\n",
      "model 2 validation (jac_thresh = 0.040000) accuracy = 0.814379\n",
      "model 2 validation (jac_thresh = 0.041000) accuracy = 0.814245\n",
      "model 2 validation (jac_thresh = 0.042000) accuracy = 0.813751\n",
      "model 2 validation (jac_thresh = 0.043000) accuracy = 0.813033\n",
      "model 2 validation (jac_thresh = 0.044000) accuracy = 0.812584\n",
      "model 2 validation (jac_thresh = 0.045000) accuracy = 0.811956\n"
     ]
    }
   ],
   "source": [
    "for jac_thresh in np.arange(0.035, 0.046, 0.001):\n",
    "    m2_v_pred = [(m2_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m2_v_pred, \"model 2 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jac_thresh of **0.04** performs best on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 test accuracy = 0.813022\n",
      "model 2 test TP | FP | TN | FN = 6590 | 1941 | 5485 | 836\n",
      "model 2 test precision = 0.772477\n",
      "model 2 test recall = 0.887423\n"
     ]
    }
   ],
   "source": [
    "m2_t_pred = [(m2_predict(uid, aid, 0.04), y) for uid, aid, y in testing_set]\n",
    "measure(m2_t_pred, \"model 2 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #3\n",
    "m3_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m3_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user\n",
    "    # has previously tagged any artist with the tags attributed to this artist by other users (tags sorted by frequency\n",
    "    # for both user and artist)\n",
    "    else:\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 validation (top_lim = 0) accuracy = 0.493448\n",
      "model 3 validation (top_lim = 1) accuracy = 0.638453\n",
      "model 3 validation (top_lim = 2) accuracy = 0.683287\n",
      "model 3 validation (top_lim = 3) accuracy = 0.708734\n",
      "model 3 validation (top_lim = 4) accuracy = 0.718966\n",
      "model 3 validation (top_lim = 5) accuracy = 0.725833\n",
      "model 3 validation (top_lim = 6) accuracy = 0.729872\n",
      "model 3 validation (top_lim = 7) accuracy = 0.732340\n",
      "model 3 validation (top_lim = 8) accuracy = 0.734494\n",
      "model 3 validation (top_lim = 9) accuracy = 0.736469\n",
      "model 3 validation (top_lim = 10) accuracy = 0.737905\n",
      "model 3 validation (top_lim = 11) accuracy = 0.738040\n",
      "model 3 validation (top_lim = 12) accuracy = 0.737995\n",
      "model 3 validation (top_lim = 13) accuracy = 0.738264\n",
      "model 3 validation (top_lim = 14) accuracy = 0.738848\n",
      "model 3 validation (top_lim = 15) accuracy = 0.738937\n",
      "model 3 validation (top_lim = 16) accuracy = 0.739117\n",
      "model 3 validation (top_lim = 17) accuracy = 0.738758\n",
      "model 3 validation (top_lim = 18) accuracy = 0.738623\n",
      "model 3 validation (top_lim = 19) accuracy = 0.737995\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "for top_lim in range(0, 20):\n",
    "    m3_v_pred = [(m3_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    measure(m3_v_pred, \"model 3 validation (top_lim = %d)\" % top_lim, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 test accuracy = 0.738621\n",
      "model 3 test TP | FP | TN | FN = 5110 | 1566 | 5860 | 2316\n",
      "model 3 test precision = 0.765428\n",
      "model 3 test recall = 0.688123\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "m3_t_pred = [(m3_predict(uid, aid, 16), y) for uid, aid, y in testing_set]\n",
    "measure(m3_t_pred, \"model 3 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #4\n",
    "m4_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m4_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user\n",
    "    # has previously tagged any artist with the tags attributed to this artist by other users (tags sorted by number of\n",
    "    # listens by the users who attributed the given tag)\n",
    "    else:\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 validation (top_lim = 15) accuracy = 0.680549\n",
      "model 4 validation (top_lim = 16) accuracy = 0.681492\n",
      "model 4 validation (top_lim = 17) accuracy = 0.682300\n",
      "model 4 validation (top_lim = 18) accuracy = 0.682479\n",
      "model 4 validation (top_lim = 19) accuracy = 0.682793\n",
      "model 4 validation (top_lim = 20) accuracy = 0.682973\n",
      "model 4 validation (top_lim = 21) accuracy = 0.683287\n",
      "model 4 validation (top_lim = 22) accuracy = 0.683107\n",
      "model 4 validation (top_lim = 23) accuracy = 0.683332\n",
      "model 4 validation (top_lim = 24) accuracy = 0.683242\n",
      "model 4 validation (top_lim = 25) accuracy = 0.683422\n",
      "model 4 validation (top_lim = 26) accuracy = 0.683466\n",
      "model 4 validation (top_lim = 27) accuracy = 0.683422\n",
      "model 4 validation (top_lim = 28) accuracy = 0.683691\n",
      "model 4 validation (top_lim = 29) accuracy = 0.683781\n",
      "model 4 validation (top_lim = 30) accuracy = 0.683781\n"
     ]
    }
   ],
   "source": [
    "# model 4 predictions\n",
    "for top_lim in range(15, 31):\n",
    "    m4_v_pred = [(m4_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    measure(m4_v_pred, \"model 4 validation (top_lim = %d)\" % top_lim, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 test accuracy = 0.681996\n",
      "model 4 test TP | FP | TN | FN = 3652 | 949 | 6477 | 3774\n",
      "model 4 test precision = 0.793740\n",
      "model 4 test recall = 0.491786\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "m4_t_pred = [(m4_predict(uid, aid, 30), y) for uid, aid, y in testing_set]\n",
    "measure(m4_t_pred, \"model 4 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #5\n",
    "m5_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m5_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].tags.keys())\n",
    "            u2s = set(train['users'][uid2].tags.keys())\n",
    "            if len(u1s | u2s) == 0:\n",
    "                return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 validation (jac_thresh = 0.000000) accuracy = 0.661521\n",
      "model 5 validation (jac_thresh = 0.050000) accuracy = 0.715780\n",
      "model 5 validation (jac_thresh = 0.100000) accuracy = 0.705771\n",
      "model 5 validation (jac_thresh = 0.150000) accuracy = 0.666996\n",
      "model 5 validation (jac_thresh = 0.200000) accuracy = 0.610223\n",
      "model 5 validation (jac_thresh = 0.250000) accuracy = 0.566780\n",
      "model 5 validation (jac_thresh = 0.300000) accuracy = 0.537160\n",
      "model 5 validation (jac_thresh = 0.350000) accuracy = 0.516605\n",
      "model 5 validation (jac_thresh = 0.400000) accuracy = 0.505386\n",
      "model 5 validation (jac_thresh = 0.450000) accuracy = 0.500135\n",
      "model 5 validation (jac_thresh = 0.500000) accuracy = 0.495736\n"
     ]
    }
   ],
   "source": [
    "# model 5 predictions\n",
    "for jac_thresh in np.arange(0, 0.55, 0.05):\n",
    "    m5_v_pred = [(m5_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m5_v_pred, \"model 5 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 validation (jac_thresh = 0.000000) accuracy = 0.661521\n",
      "model 5 validation (jac_thresh = 0.010000) accuracy = 0.661521\n",
      "model 5 validation (jac_thresh = 0.020000) accuracy = 0.680056\n",
      "model 5 validation (jac_thresh = 0.030000) accuracy = 0.693654\n",
      "model 5 validation (jac_thresh = 0.040000) accuracy = 0.708554\n",
      "model 5 validation (jac_thresh = 0.050000) accuracy = 0.715780\n",
      "model 5 validation (jac_thresh = 0.060000) accuracy = 0.719864\n",
      "model 5 validation (jac_thresh = 0.070000) accuracy = 0.717934\n",
      "model 5 validation (jac_thresh = 0.080000) accuracy = 0.715690\n",
      "model 5 validation (jac_thresh = 0.090000) accuracy = 0.712548\n"
     ]
    }
   ],
   "source": [
    "# model 5 predictions\n",
    "for jac_thresh in np.arange(0, 0.1, 0.01):\n",
    "    m5_v_pred = [(m5_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m5_v_pred, \"model 5 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 test accuracy = 0.717277\n",
      "model 5 test TP | FP | TN | FN = 5142 | 1915 | 5511 | 2284\n",
      "model 5 test precision = 0.728638\n",
      "model 5 test recall = 0.692432\n"
     ]
    }
   ],
   "source": [
    "m5_t_pred = [(m5_predict(uid, aid, 0.06), y) for uid, aid, y in testing_set]\n",
    "measure(m5_t_pred, \"model 5 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #6\n",
    "m6_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m6_predict(uid, aid):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        for uid2 in train['users'][uid].friends:\n",
    "            if len(train['users'][uid2].friends & train['artists'][aid].user_listens) > 0:\n",
    "                return True\n",
    "        return len(train['users'][uid].friends & train['artists'][aid].user_listens) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 6 validation accuracy = 0.757697\n",
      "model 6 validation TP | FP | TN | FN = 8234 | 2492 | 8649 | 2907\n",
      "model 6 validation precision = 0.767667\n",
      "model 6 validation recall = 0.739072\n"
     ]
    }
   ],
   "source": [
    "# model 6 predictions\n",
    "m6_v_pred = [(m6_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "measure(m6_v_pred, \"model 6 validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 6 test accuracy = 0.753838\n",
      "model 6 test TP | FP | TN | FN = 5442 | 1672 | 5754 | 1984\n",
      "model 6 test precision = 0.764970\n",
      "model 6 test recall = 0.732831\n"
     ]
    }
   ],
   "source": [
    "# model 6 predictions\n",
    "m6_t_pred = [(m6_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "measure(m6_t_pred, \"model 6 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #7\n",
    "m7_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m7_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in (train['artists'][aid].user_listens & train['users'][uid].friends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 7 validation (jac_thresh = 0.000000) accuracy = 0.681806\n",
      "model 7 validation (jac_thresh = 0.050000) accuracy = 0.655462\n",
      "model 7 validation (jac_thresh = 0.100000) accuracy = 0.605691\n",
      "model 7 validation (jac_thresh = 0.150000) accuracy = 0.564536\n",
      "model 7 validation (jac_thresh = 0.200000) accuracy = 0.534871\n",
      "model 7 validation (jac_thresh = 0.250000) accuracy = 0.512521\n",
      "model 7 validation (jac_thresh = 0.300000) accuracy = 0.500135\n",
      "model 7 validation (jac_thresh = 0.350000) accuracy = 0.494211\n",
      "model 7 validation (jac_thresh = 0.400000) accuracy = 0.493762\n",
      "model 7 validation (jac_thresh = 0.450000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.500000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.550000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.600000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.650000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.700000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.750000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.800000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.850000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.900000) accuracy = 0.493448\n",
      "model 7 validation (jac_thresh = 0.950000) accuracy = 0.493448\n"
     ]
    }
   ],
   "source": [
    "# model 7 predictions\n",
    "for jac_thresh in np.arange(0, 1, 0.05):\n",
    "    m7_v_pred = [(m7_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m7_v_pred, \"model 7 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #8\n",
    "m8_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m8_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friend's tags match the artist's tags, and if not, if any of the user's tags match the artist's tags\n",
    "    else:\n",
    "        for uid2 in train['users'][uid].friends:\n",
    "            utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid2].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "            atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "            if len(utags & atags) > 0:\n",
    "                return True\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8 validation (top_lim = 0) accuracy = 0.501840\n",
      "model 8 validation (top_lim = 1) accuracy = 0.721883\n",
      "model 8 validation (top_lim = 2) accuracy = 0.741630\n",
      "model 8 validation (top_lim = 3) accuracy = 0.750381\n",
      "model 8 validation (top_lim = 4) accuracy = 0.754780\n",
      "model 8 validation (top_lim = 5) accuracy = 0.756979\n",
      "model 8 validation (top_lim = 6) accuracy = 0.758505\n",
      "model 8 validation (top_lim = 7) accuracy = 0.759088\n",
      "model 8 validation (top_lim = 8) accuracy = 0.759851\n",
      "model 8 validation (top_lim = 9) accuracy = 0.760075\n",
      "model 8 validation (top_lim = 10) accuracy = 0.759627\n",
      "model 8 validation (top_lim = 11) accuracy = 0.759088\n",
      "model 8 validation (top_lim = 12) accuracy = 0.759223\n",
      "model 8 validation (top_lim = 13) accuracy = 0.758639\n",
      "model 8 validation (top_lim = 14) accuracy = 0.758550\n",
      "model 8 validation (top_lim = 15) accuracy = 0.758101\n",
      "model 8 validation (top_lim = 16) accuracy = 0.757921\n",
      "model 8 validation (top_lim = 17) accuracy = 0.757831\n",
      "model 8 validation (top_lim = 18) accuracy = 0.757383\n",
      "model 8 validation (top_lim = 19) accuracy = 0.757113\n"
     ]
    }
   ],
   "source": [
    "# model 8 predictions\n",
    "for top_lim in range(0, 20):\n",
    "    m8_v_pred = [(m8_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    measure(m8_v_pred, \"model 8 validation (top_lim = %d)\" % top_lim, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8 test accuracy = 0.759561\n",
      "model 8 test TP | FP | TN | FN = 5778 | 1923 | 5503 | 1648\n",
      "model 8 test precision = 0.750292\n",
      "model 8 test recall = 0.778077\n"
     ]
    }
   ],
   "source": [
    "m8_t_pred = [(m8_predict(uid, aid, 9), y) for uid, aid, y in testing_set]\n",
    "measure(m8_t_pred, \"model 8 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #10\n",
    "m9_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m9_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(u1s, u2s):\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        for uid2 in train['artists'][aid].user_listens:\n",
    "            u1s = set(train['users'][uid].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            u1s2 = set(train['users'][uid].tags.keys())\n",
    "            u2s2 = set(train['users'][uid2].tags.keys())\n",
    "            jac = (jaccard(u1s, u2s) + jaccard(u1s2, u2s2)) / 2.\n",
    "            if jac > jac_thresh:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 9 validation (jac_thresh = 0.000000) accuracy = 0.640472\n",
      "model 9 validation (jac_thresh = 0.050000) accuracy = 0.783592\n",
      "model 9 validation (jac_thresh = 0.100000) accuracy = 0.725698\n",
      "model 9 validation (jac_thresh = 0.150000) accuracy = 0.632080\n",
      "model 9 validation (jac_thresh = 0.200000) accuracy = 0.558478\n",
      "model 9 validation (jac_thresh = 0.250000) accuracy = 0.521228\n",
      "model 9 validation (jac_thresh = 0.300000) accuracy = 0.508527\n",
      "model 9 validation (jac_thresh = 0.350000) accuracy = 0.504712\n",
      "model 9 validation (jac_thresh = 0.400000) accuracy = 0.503411\n",
      "model 9 validation (jac_thresh = 0.450000) accuracy = 0.502872\n",
      "model 9 validation (jac_thresh = 0.500000) accuracy = 0.502513\n"
     ]
    }
   ],
   "source": [
    "# model 9 predictions\n",
    "for jac_thresh in np.arange(0, 0.55, 0.05):\n",
    "    m9_v_pred = [(m9_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m9_v_pred, \"model 9 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 9 validation (jac_thresh = 0.000000) accuracy = 0.640472\n",
      "model 9 validation (jac_thresh = 0.010000) accuracy = 0.692487\n",
      "model 9 validation (jac_thresh = 0.020000) accuracy = 0.744188\n",
      "model 9 validation (jac_thresh = 0.030000) accuracy = 0.770712\n",
      "model 9 validation (jac_thresh = 0.040000) accuracy = 0.782336\n",
      "model 9 validation (jac_thresh = 0.050000) accuracy = 0.783592\n",
      "model 9 validation (jac_thresh = 0.060000) accuracy = 0.780585\n",
      "model 9 validation (jac_thresh = 0.070000) accuracy = 0.772013\n",
      "model 9 validation (jac_thresh = 0.080000) accuracy = 0.757652\n",
      "model 9 validation (jac_thresh = 0.090000) accuracy = 0.742707\n",
      "model 9 validation (jac_thresh = 0.100000) accuracy = 0.725698\n"
     ]
    }
   ],
   "source": [
    "# model 9 predictions\n",
    "for jac_thresh in np.arange(0, 0.11, 0.01):\n",
    "    m9_v_pred = [(m9_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    measure(m9_v_pred, \"model 9 validation (jac_thresh = %f)\" % jac_thresh, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #10\n",
    "m10_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m10_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(u1s, u2s):\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        for uid2 in train['artists'][aid].user_listens:\n",
    "            u1s = set(train['users'][uid].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            u1s2 = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].tags.iteritems()], reverse = True)][:top_lim])\n",
    "            u2s2 = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid2].tags.iteritems()], reverse = True)][:top_lim])\n",
    "            jac = (jaccard(u1s, u2s) + jaccard(u1s2, u2s2)) / 2.\n",
    "            if jac > 0.04:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 validation (top_lim = 17) accuracy = 0.778566\n",
      "model 10 validation (top_lim = 18) accuracy = 0.777264\n",
      "model 10 validation (top_lim = 19) accuracy = 0.776142\n",
      "model 10 validation (top_lim = 20) accuracy = 0.775065\n",
      "model 10 validation (top_lim = 21) accuracy = 0.778252\n",
      "model 10 validation (top_lim = 22) accuracy = 0.778835\n",
      "model 10 validation (top_lim = 23) accuracy = 0.778386\n",
      "model 10 validation (top_lim = 24) accuracy = 0.779777\n",
      "model 10 validation (top_lim = 25) accuracy = 0.779373\n"
     ]
    }
   ],
   "source": [
    "# model 10 predictions\n",
    "for top_lim in range(17, 30):\n",
    "    m10_v_pred = [(m10_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    measure(m10_v_pred, \"model 10 validation (top_lim = %d)\" % top_lim, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #11\n",
    "m11_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m11_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set([a for f, a in sorted([(f, a) for a, f in train['users'][uid].artist_listens.iteritems()], reverse = True)][:top_lim])\n",
    "            u2s = set([a for f, a in sorted([(f, a) for a, f in train['users'][uid2].artist_listens.iteritems()], reverse = True)][:top_lim])\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > 0.04 for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 11 validation accuracy (top_lim = 15) = 0.800557\n",
      "model 11 validation accuracy (top_lim = 16) = 0.802800\n",
      "model 11 validation accuracy (top_lim = 17) = 0.804551\n",
      "model 11 validation accuracy (top_lim = 18) = 0.806481\n",
      "model 11 validation accuracy (top_lim = 19) = 0.808365\n",
      "model 11 validation accuracy (top_lim = 20) = 0.809667\n",
      "model 11 validation accuracy (top_lim = 21) = 0.810924\n",
      "model 11 validation accuracy (top_lim = 22) = 0.810071\n",
      "model 11 validation accuracy (top_lim = 23) = 0.810250\n",
      "model 11 validation accuracy (top_lim = 24) = 0.809577\n",
      "model 11 validation accuracy (top_lim = 25) = 0.808410\n"
     ]
    }
   ],
   "source": [
    "for top_lim in range(15, 26):\n",
    "    m11_v_pred = [(m11_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m11_v_acc = sum([p == y for p, y in m11_v_pred]) * 1. / len(m11_v_pred)\n",
    "    print \"model 11 validation accuracy (top_lim = %d) = %f\" % (top_lim, m11_v_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
