{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class artist:\n",
    "    def __init__(self, aid = -1, name = \"\", url = \"\"):\n",
    "        self.aid = aid\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.listens = 0\n",
    "        self.user_listens = set()\n",
    "        self.tags = defaultdict(int)\n",
    "        self.weighted_tags = defaultdict(int)\n",
    "\n",
    "class tag:\n",
    "    def __init__(self, tid = 0, tag = \"\", uid = -1, aid = -1):\n",
    "        self.uid = uid\n",
    "        self.aid = aid\n",
    "        self.tag = tag\n",
    "        self.uid = uid\n",
    "        self.aid = aid\n",
    "\n",
    "class user:\n",
    "    def __init__(self, uid = -1):\n",
    "        self.uid = uid\n",
    "        self.friends = set()\n",
    "        self.artist_listens = {}\n",
    "        self.listens = 0\n",
    "        self.artist_tags = defaultdict(set)\n",
    "        self.tags = defaultdict(int)\n",
    "        self.weighted_tags = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_artists: ['url', 'pictureURL', 'id', 'name']\n",
      "data_tags: ['tagID', 'tagValue']\n",
      "data_user_artists: ['artistID', 'userID', 'weight']\n",
      "data_user_friends: ['userID', 'friendID']\n",
      "data_user_taggedartists: ['tagID', 'userID', 'month', 'artistID', 'year', 'day']\n"
     ]
    }
   ],
   "source": [
    "with open('data/artists.dat') as csvf:\n",
    "    data_artists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_artists: \" + str(data_artists[0].keys())\n",
    "\n",
    "with open('data/tags.dat') as csvf:\n",
    "    data_tags = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_tags: \" + str(data_tags[0].keys())\n",
    "\n",
    "with open('data/user_artists.dat') as csvf:\n",
    "    data_user_artists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_artists: \" + str(data_user_artists[0].keys())\n",
    "\n",
    "with open('data/user_friends.dat') as csvf:\n",
    "    data_user_friends = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_friends: \" + str(data_user_friends[0].keys())\n",
    "\n",
    "with open('data/user_taggedartists.dat') as csvf:\n",
    "    data_user_taggedartists = [row for row in csv.DictReader(csvf, delimiter = '\\t')]\n",
    "    print \"data_user_taggedartists: \" + str(data_user_taggedartists[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.shuffle(data_artists)\n",
    "np.random.shuffle(data_tags)\n",
    "np.random.shuffle(data_user_artists)\n",
    "np.random.shuffle(data_user_friends)\n",
    "np.random.shuffle(data_user_taggedartists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get all the unique users\n",
    "users = {}\n",
    "# for d in data_user_artists: users[d['userID']] = user(d['userID'])\n",
    "# for d in data_user_friends: users[d['userID']] = user(d['userID'])\n",
    "# for d in data_user_taggedartists: users[d['userID']] = user(d['userID'])\n",
    "# then, get all the unique artists\n",
    "artists = {d['id']: artist(d['id'], d['name'], d['url']) for d in data_artists}\n",
    "# finally, get all the unique tags\n",
    "tags = {d['tagID']: tag(d['tagID'], d['tagValue']) for d in data_tags}\n",
    "    \n",
    "train = {\n",
    "    'set': data_user_artists[:int(len(data_user_artists) * .8)],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "test = {\n",
    "    'set': data_user_artists[int(len(data_user_artists) * .8):int(len(data_user_artists) * .88)],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "valid = {\n",
    "    'set': data_user_artists[int(len(data_user_artists) * .88):],\n",
    "    'users': {},\n",
    "    'artists': {}\n",
    "}\n",
    "\n",
    "for a in [train, test, valid]:\n",
    "    for s in a['set']:\n",
    "        uid = s['userID']\n",
    "        aid = s['artistID']\n",
    "        if uid not in users:\n",
    "            users[uid] = user(uid)\n",
    "        if uid not in a['users']:\n",
    "            a['users'][uid] = user(uid)\n",
    "        if aid not in a['artists']:\n",
    "            a['artists'][aid] = artist(aid, artists[aid].name, artists[aid].url)\n",
    "        if aid not in a['users'][uid].artist_listens:\n",
    "            a['users'][uid].artist_listens[aid] = 0\n",
    "        a['users'][uid].artist_listens[aid] = int(s['weight'])\n",
    "        a['users'][uid].listens += int(s['weight'])\n",
    "        a['artists'][aid].listens += int(s['weight'])\n",
    "        a['artists'][aid].user_listens.add(uid)\n",
    "        artists[aid].listens += int(s['weight'])\n",
    "\n",
    "# build the rest of the data now that we know which users/artists are in each set\n",
    "for d in data_user_friends:\n",
    "    for a in [train, test, valid]:\n",
    "        if d['userID'] in a['users'] and d['friendID'] in a['users']:\n",
    "            a['users'][d['userID']].friends.add(d['friendID'])\n",
    "            a['users'][d['friendID']].friends.add(d['userID'])\n",
    "for d in data_user_taggedartists:\n",
    "    for a in [train, test, valid]:\n",
    "        if d['userID'] in a['users'] and d['artistID'] in a['artists']:\n",
    "            t = tag(d['tagID'], tags[d['tagID']].tag, d['userID'], d['artistID'])\n",
    "            a['users'][d['userID']].artist_tags[d['artistID']].add(t)\n",
    "            a['users'][d['userID']].tags[d['tagID']] += 1\n",
    "            if d['artistID'] in a['users'][d['userID']].artist_listens:\n",
    "                a['users'][d['userID']].weighted_tags[d['tagID']] += a['users'][d['userID']].artist_listens[d['artistID']]\n",
    "                a['artists'][d['artistID']].weighted_tags[d['tagID']] += a['users'][d['userID']].artist_listens[d['artistID']]\n",
    "            a['artists'][d['artistID']].tags[d['tagID']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training users = 1892\n",
      "# training artists = 15382\n",
      "# testing users = 1840\n",
      "# testing artists = 3475\n",
      "# validation users = 1872\n",
      "# validation artists = 4566\n"
     ]
    }
   ],
   "source": [
    "for a, s in [(train, 'training'), (test, 'testing'), (valid, 'validation')]:\n",
    "    print \"# %s users = %d\" % (s, len(a['users'].values()))\n",
    "    print \"# %s artists = %d\" % (s, len(a['artists'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive samples in test set: 7426\n",
      "# of samples in test set: 14852\n"
     ]
    }
   ],
   "source": [
    "# grow the testing set with negative samples\n",
    "testing_set = []\n",
    "for uid, u in test['users'].iteritems():\n",
    "    testing_set.extend([(uid, aid, True) for aid in u.artist_listens.keys()])\n",
    "i = 0\n",
    "lim = len(testing_set)\n",
    "print \"# of positive samples in test set: %d\" % lim\n",
    "while i < lim:\n",
    "    uid = np.random.choice(users.keys())\n",
    "    aid = np.random.choice(artists.keys())\n",
    "    if uid in test['users'] and aid not in test['users'][uid].artist_listens:\n",
    "        testing_set.append((uid, aid, False))\n",
    "        i += 1\n",
    "print \"# of samples in test set: %d\" % len(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive samples in validation set: 11141\n",
      "# of samples in validation set: 22282\n"
     ]
    }
   ],
   "source": [
    "# grow the validation set with negative samples\n",
    "validation_set = []\n",
    "for uid, u in valid['users'].iteritems():\n",
    "    validation_set.extend([(uid, aid, True) for aid in u.artist_listens.keys()])\n",
    "i = 0\n",
    "lim = len(validation_set)\n",
    "print \"# of positive samples in validation set: %d\" % lim\n",
    "while i < lim:\n",
    "    uid = np.random.choice(users.keys())\n",
    "    aid = np.random.choice(artists.keys())\n",
    "    if uid in valid['users'] and aid not in valid['users'][uid].artist_listens:\n",
    "        validation_set.append((uid, aid, False))\n",
    "        i += 1\n",
    "print \"# of samples in validation set: %d\" % len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all the artists by most listened\n",
    "top_artists = [(a.listens, a) for aid, a in train['artists'].iteritems()]\n",
    "top_artists = sorted(top_artists, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg_artists_per_user = np.mean([len(u.artist_listens.keys()) for _, u in train['users'].iteritems()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #1\n",
    "m1_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m1_predict(uid, aid):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        return len(train['users'][uid].friends & train['artists'][aid].user_listens) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 validation accuracy = 0.684274\n"
     ]
    }
   ],
   "source": [
    "# model 1 predictions\n",
    "m1_v_pred = [(m1_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "m1_v_acc = sum([p == y for p, y in m1_v_pred]) * 1. / len(m1_v_pred)\n",
    "print \"model 1 validation accuracy = %f\" % m1_v_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 test accuracy = 0.682669\n"
     ]
    }
   ],
   "source": [
    "# testing set performance\n",
    "m1_t_pred = [(m1_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "m1_t_acc = sum([p == y for p, y in m1_t_pred]) * 1. / len(m1_t_pred)\n",
    "print \"model 1 test accuracy = %f\" % m1_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #2\n",
    "m2_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m2_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 validation accuracy (jac_thresh = 0.000000) = 0.707656\n",
      "model 2 validation accuracy (jac_thresh = 0.005000) = 0.707656\n",
      "model 2 validation accuracy (jac_thresh = 0.010000) = 0.707656\n",
      "model 2 validation accuracy (jac_thresh = 0.015000) = 0.779104\n",
      "model 2 validation accuracy (jac_thresh = 0.020000) = 0.779867\n",
      "model 2 validation accuracy (jac_thresh = 0.025000) = 0.794632\n",
      "model 2 validation accuracy (jac_thresh = 0.030000) = 0.807603\n",
      "model 2 validation accuracy (jac_thresh = 0.035000) = 0.808231\n",
      "model 2 validation accuracy (jac_thresh = 0.040000) = 0.814379\n",
      "model 2 validation accuracy (jac_thresh = 0.045000) = 0.811956\n",
      "model 2 validation accuracy (jac_thresh = 0.050000) = 0.812853\n",
      "model 2 validation accuracy (jac_thresh = 0.055000) = 0.808769\n",
      "model 2 validation accuracy (jac_thresh = 0.060000) = 0.805269\n",
      "model 2 validation accuracy (jac_thresh = 0.065000) = 0.801409\n",
      "model 2 validation accuracy (jac_thresh = 0.070000) = 0.792299\n",
      "model 2 validation accuracy (jac_thresh = 0.075000) = 0.784849\n",
      "model 2 validation accuracy (jac_thresh = 0.080000) = 0.778027\n",
      "model 2 validation accuracy (jac_thresh = 0.085000) = 0.769769\n",
      "model 2 validation accuracy (jac_thresh = 0.090000) = 0.762050\n",
      "model 2 validation accuracy (jac_thresh = 0.095000) = 0.752940\n",
      "model 2 validation accuracy (jac_thresh = 0.100000) = 0.742258\n"
     ]
    }
   ],
   "source": [
    "# model 2 predictions\n",
    "for jac_thresh in np.arange(0, 0.105, 0.005):\n",
    "    m2_v_pred = [(m2_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m2_v_acc = sum([p == y for p, y in m2_v_pred]) * 1. / len(m2_v_pred)\n",
    "    print \"model 2 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m2_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 validation accuracy (jac_thresh = 0.035000) = 0.808231\n",
      "model 2 validation accuracy (jac_thresh = 0.036000) = 0.808904\n",
      "model 2 validation accuracy (jac_thresh = 0.037000) = 0.810385\n",
      "model 2 validation accuracy (jac_thresh = 0.038000) = 0.813527\n",
      "model 2 validation accuracy (jac_thresh = 0.039000) = 0.813975\n",
      "model 2 validation accuracy (jac_thresh = 0.040000) = 0.814379\n",
      "model 2 validation accuracy (jac_thresh = 0.041000) = 0.814245\n",
      "model 2 validation accuracy (jac_thresh = 0.042000) = 0.813751\n",
      "model 2 validation accuracy (jac_thresh = 0.043000) = 0.813033\n",
      "model 2 validation accuracy (jac_thresh = 0.044000) = 0.812584\n",
      "model 2 validation accuracy (jac_thresh = 0.045000) = 0.811956\n"
     ]
    }
   ],
   "source": [
    "for jac_thresh in np.arange(0.035, 0.046, 0.001):\n",
    "    m2_v_pred = [(m2_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m2_v_acc = sum([p == y for p, y in m2_v_pred]) * 1. / len(m2_v_pred)\n",
    "    print \"model 2 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m2_v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jac_thresh of **0.04** performs best on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 test accuracy = 0.813022\n"
     ]
    }
   ],
   "source": [
    "m2_t_pred = [(m2_predict(uid, aid, 0.04), y) for uid, aid, y in testing_set]\n",
    "m2_t_acc = sum([p == y for p, y in m2_t_pred]) * 1. / len(m2_t_pred)\n",
    "print \"model 2 test accuracy = %f\" % m2_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline validation accuracy = 0.570191\n",
      "baseline test accuracy = 0.570159\n"
     ]
    }
   ],
   "source": [
    "# predict True if the artist is in the top 50 artists, and False otherwise\n",
    "baseline_top_artists = set([a.aid for _, a in top_artists[:50]])\n",
    "def baseline_predict(uid, aid):\n",
    "    return aid in baseline_top_artists\n",
    "\n",
    "baseline_v_pred = [(baseline_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "baseline_v_acc = sum([p == y for p, y in baseline_v_pred]) * 1. / len(baseline_v_pred)\n",
    "print \"baseline validation accuracy = %f\" % baseline_v_acc\n",
    "\n",
    "baseline_t_pred = [(baseline_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "baseline_t_acc = sum([p == y for p, y in baseline_t_pred]) * 1. / len(baseline_t_pred)\n",
    "print \"baseline test accuracy = %f\" % baseline_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #3\n",
    "m3_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m3_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user\n",
    "    # has previously tagged any artist with the tags attributed to this artist by other users (tags sorted by frequency\n",
    "    # for both user and artist)\n",
    "    else:\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 validation accuracy (top_lim = 0) = 0.493448\n",
      "model 3 validation accuracy (top_lim = 1) = 0.638453\n",
      "model 3 validation accuracy (top_lim = 2) = 0.683287\n",
      "model 3 validation accuracy (top_lim = 3) = 0.708734\n",
      "model 3 validation accuracy (top_lim = 4) = 0.718966\n",
      "model 3 validation accuracy (top_lim = 5) = 0.725833\n",
      "model 3 validation accuracy (top_lim = 6) = 0.729872\n",
      "model 3 validation accuracy (top_lim = 7) = 0.732340\n",
      "model 3 validation accuracy (top_lim = 8) = 0.734494\n",
      "model 3 validation accuracy (top_lim = 9) = 0.736469\n",
      "model 3 validation accuracy (top_lim = 10) = 0.737905\n",
      "model 3 validation accuracy (top_lim = 11) = 0.738040\n",
      "model 3 validation accuracy (top_lim = 12) = 0.737995\n",
      "model 3 validation accuracy (top_lim = 13) = 0.738264\n",
      "model 3 validation accuracy (top_lim = 14) = 0.738848\n",
      "model 3 validation accuracy (top_lim = 15) = 0.738937\n",
      "model 3 validation accuracy (top_lim = 16) = 0.739117\n",
      "model 3 validation accuracy (top_lim = 17) = 0.738758\n",
      "model 3 validation accuracy (top_lim = 18) = 0.738623\n",
      "model 3 validation accuracy (top_lim = 19) = 0.737995\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "for top_lim in range(0, 20):\n",
    "    m3_v_pred = [(m3_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m3_v_acc = sum([p == y for p, y in m3_v_pred]) * 1. / len(m3_v_pred)\n",
    "    print \"model 3 validation accuracy (top_lim = %d) = %f\" % (top_lim, m3_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 test accuracy = 0.738621\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "m3_t_pred = [(m3_predict(uid, aid, 16), y) for uid, aid, y in testing_set]\n",
    "m3_t_acc = sum([p == y for p, y in m3_t_pred]) * 1. / len(m3_t_pred)\n",
    "print \"model 3 test accuracy = %f\" % m3_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #4\n",
    "m4_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m4_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user\n",
    "    # has previously tagged any artist with the tags attributed to this artist by other users (tags sorted by number of\n",
    "    # listens by the users who attributed the given tag)\n",
    "    else:\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 validation accuracy (top_lim = 0) = 0.493448\n",
      "model 4 validation accuracy (top_lim = 1) = 0.581007\n",
      "model 4 validation accuracy (top_lim = 2) = 0.618975\n",
      "model 4 validation accuracy (top_lim = 3) = 0.639934\n",
      "model 4 validation accuracy (top_lim = 4) = 0.649493\n",
      "model 4 validation accuracy (top_lim = 5) = 0.657122\n",
      "model 4 validation accuracy (top_lim = 6) = 0.662867\n",
      "model 4 validation accuracy (top_lim = 7) = 0.667669\n",
      "model 4 validation accuracy (top_lim = 8) = 0.670227\n",
      "model 4 validation accuracy (top_lim = 9) = 0.673414\n",
      "model 4 validation accuracy (top_lim = 10) = 0.675523\n",
      "model 4 validation accuracy (top_lim = 11) = 0.677138\n",
      "model 4 validation accuracy (top_lim = 12) = 0.678305\n",
      "model 4 validation accuracy (top_lim = 13) = 0.678709\n",
      "model 4 validation accuracy (top_lim = 14) = 0.679382\n",
      "model 4 validation accuracy (top_lim = 15) = 0.680549\n",
      "model 4 validation accuracy (top_lim = 16) = 0.681492\n",
      "model 4 validation accuracy (top_lim = 17) = 0.682300\n",
      "model 4 validation accuracy (top_lim = 18) = 0.682479\n",
      "model 4 validation accuracy (top_lim = 19) = 0.682793\n"
     ]
    }
   ],
   "source": [
    "# model 4 predictions\n",
    "for top_lim in range(0, 20):\n",
    "    m4_v_pred = [(m4_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m4_v_acc = sum([p == y for p, y in m4_v_pred]) * 1. / len(m4_v_pred)\n",
    "    print \"model 4 validation accuracy (top_lim = %d) = %f\" % (top_lim, m4_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 test accuracy = 0.682938\n"
     ]
    }
   ],
   "source": [
    "# model 3 predictions\n",
    "m4_t_pred = [(m4_predict(uid, aid, 50), y) for uid, aid, y in testing_set]\n",
    "m4_t_acc = sum([p == y for p, y in m4_t_pred]) * 1. / len(m4_t_pred)\n",
    "print \"model 4 test accuracy = %f\" % m4_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #5\n",
    "m5_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m5_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].tags.keys())\n",
    "            u2s = set(train['users'][uid2].tags.keys())\n",
    "            if len(u1s | u2s) == 0:\n",
    "                return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 validation accuracy (jac_thresh = 0.000000) = 0.661521\n",
      "model 5 validation accuracy (jac_thresh = 0.050000) = 0.715780\n",
      "model 5 validation accuracy (jac_thresh = 0.100000) = 0.705771\n",
      "model 5 validation accuracy (jac_thresh = 0.150000) = 0.666996\n",
      "model 5 validation accuracy (jac_thresh = 0.200000) = 0.610223\n",
      "model 5 validation accuracy (jac_thresh = 0.250000) = 0.566780\n",
      "model 5 validation accuracy (jac_thresh = 0.300000) = 0.537160\n",
      "model 5 validation accuracy (jac_thresh = 0.350000) = 0.516605\n",
      "model 5 validation accuracy (jac_thresh = 0.400000) = 0.505386\n",
      "model 5 validation accuracy (jac_thresh = 0.450000) = 0.500135\n",
      "model 5 validation accuracy (jac_thresh = 0.500000) = 0.495736\n"
     ]
    }
   ],
   "source": [
    "# model 5 predictions\n",
    "for jac_thresh in np.arange(0, 0.55, 0.05):\n",
    "    m5_v_pred = [(m5_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m5_v_acc = sum([p == y for p, y in m5_v_pred]) * 1. / len(m5_v_pred)\n",
    "    print \"model 5 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m5_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 validation accuracy (jac_thresh = 0.000000) = 0.661521\n",
      "model 5 validation accuracy (jac_thresh = 0.010000) = 0.661521\n",
      "model 5 validation accuracy (jac_thresh = 0.020000) = 0.680056\n",
      "model 5 validation accuracy (jac_thresh = 0.030000) = 0.693654\n",
      "model 5 validation accuracy (jac_thresh = 0.040000) = 0.708554\n",
      "model 5 validation accuracy (jac_thresh = 0.050000) = 0.715780\n",
      "model 5 validation accuracy (jac_thresh = 0.060000) = 0.719864\n",
      "model 5 validation accuracy (jac_thresh = 0.070000) = 0.717934\n",
      "model 5 validation accuracy (jac_thresh = 0.080000) = 0.715690\n",
      "model 5 validation accuracy (jac_thresh = 0.090000) = 0.712548\n"
     ]
    }
   ],
   "source": [
    "# model 5 predictions\n",
    "for jac_thresh in np.arange(0, 0.1, 0.01):\n",
    "    m5_v_pred = [(m5_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m5_v_acc = sum([p == y for p, y in m5_v_pred]) * 1. / len(m5_v_pred)\n",
    "    print \"model 5 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m5_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 validation accuracy = 0.717277\n"
     ]
    }
   ],
   "source": [
    "m5_t_pred = [(m5_predict(uid, aid, 0.06), y) for uid, aid, y in testing_set]\n",
    "m5_t_acc = sum([p == y for p, y in m5_t_pred]) * 1. / len(m5_t_pred)\n",
    "print \"model 5 validation accuracy = %f\" % m5_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friends of Friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #6\n",
    "m6_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m6_predict(uid, aid):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        for uid2 in train['users'][uid].friends:\n",
    "            if len(train['users'][uid2].friends & train['artists'][aid].user_listens) > 0:\n",
    "                return True\n",
    "        return False\n",
    "#         return len(train['users'][uid].friends & train['artists'][aid].user_listens) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 6 validation accuracy = 0.752401\n"
     ]
    }
   ],
   "source": [
    "# model 6 predictions\n",
    "m6_v_pred = [(m6_predict(uid, aid), y) for uid, aid, y in validation_set]\n",
    "m6_v_acc = sum([p == y for p, y in m6_v_pred]) * 1. / len(m6_v_pred)\n",
    "print \"model 6 validation accuracy = %f\" % m6_v_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 6 test accuracy = 0.747509\n"
     ]
    }
   ],
   "source": [
    "# model 6 predictions\n",
    "m6_t_pred = [(m6_predict(uid, aid), y) for uid, aid, y in testing_set]\n",
    "m6_t_acc = sum([p == y for p, y in m6_t_pred]) * 1. / len(m6_t_pred)\n",
    "print \"model 6 test accuracy = %f\" % m6_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #7\n",
    "m7_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m7_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > train_avg_artists_per_user\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friends have listened to this artist and False otherwise\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set(train['users'][uid1].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > jac_thresh for uid2 in (train['artists'][aid].user_listens & train['users'][uid].friends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 7 validation accuracy (jac_thresh = 0.000000) = 0.681806\n",
      "model 7 validation accuracy (jac_thresh = 0.050000) = 0.655462\n",
      "model 7 validation accuracy (jac_thresh = 0.100000) = 0.605691\n",
      "model 7 validation accuracy (jac_thresh = 0.150000) = 0.564536\n",
      "model 7 validation accuracy (jac_thresh = 0.200000) = 0.534871\n",
      "model 7 validation accuracy (jac_thresh = 0.250000) = 0.512521\n",
      "model 7 validation accuracy (jac_thresh = 0.300000) = 0.500135\n",
      "model 7 validation accuracy (jac_thresh = 0.350000) = 0.494211\n",
      "model 7 validation accuracy (jac_thresh = 0.400000) = 0.493762\n",
      "model 7 validation accuracy (jac_thresh = 0.450000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.500000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.550000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.600000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.650000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.700000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.750000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.800000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.850000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.900000) = 0.493448\n",
      "model 7 validation accuracy (jac_thresh = 0.950000) = 0.493448\n"
     ]
    }
   ],
   "source": [
    "# model 7 predictions\n",
    "for jac_thresh in np.arange(0, 1, 0.05):\n",
    "    m7_v_pred = [(m7_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m7_v_acc = sum([p == y for p, y in m7_v_pred]) * 1. / len(m7_v_pred)\n",
    "    print \"model 7 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m7_v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #8\n",
    "m8_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m8_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if any of this\n",
    "    # user's friend's tags match the artist's tags, and if not, if any of the user's tags match the artist's tags\n",
    "    else:\n",
    "        for uid2 in train['users'][uid].friends:\n",
    "            utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid2].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "            atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "            if len(utags & atags) > 0:\n",
    "                return True\n",
    "        utags = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].weighted_tags.iteritems()], reverse = True)][:top_lim])\n",
    "        atags = set([t for f, t in sorted([(f, t) for t, f in train['artists'][aid].weighted_tags.iteritems()], reverse = True)])\n",
    "        return len(utags & atags) > 0\n",
    "#         return len(train['users'][uid].friends & train['artists'][aid].user_listens) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8 validation accuracy (top_lim = 0) = 0.501840\n",
      "model 8 validation accuracy (top_lim = 1) = 0.721883\n",
      "model 8 validation accuracy (top_lim = 2) = 0.741630\n",
      "model 8 validation accuracy (top_lim = 3) = 0.750381\n",
      "model 8 validation accuracy (top_lim = 4) = 0.754780\n",
      "model 8 validation accuracy (top_lim = 5) = 0.756979\n",
      "model 8 validation accuracy (top_lim = 6) = 0.758505\n",
      "model 8 validation accuracy (top_lim = 7) = 0.759088\n",
      "model 8 validation accuracy (top_lim = 8) = 0.759851\n",
      "model 8 validation accuracy (top_lim = 9) = 0.760075\n",
      "model 8 validation accuracy (top_lim = 10) = 0.759627\n",
      "model 8 validation accuracy (top_lim = 11) = 0.759088\n",
      "model 8 validation accuracy (top_lim = 12) = 0.759223\n",
      "model 8 validation accuracy (top_lim = 13) = 0.758639\n",
      "model 8 validation accuracy (top_lim = 14) = 0.758550\n",
      "model 8 validation accuracy (top_lim = 15) = 0.758101\n",
      "model 8 validation accuracy (top_lim = 16) = 0.757921\n",
      "model 8 validation accuracy (top_lim = 17) = 0.757831\n",
      "model 8 validation accuracy (top_lim = 18) = 0.757383\n",
      "model 8 validation accuracy (top_lim = 19) = 0.757113\n"
     ]
    }
   ],
   "source": [
    "# model 8 predictions\n",
    "for top_lim in range(0, 20):\n",
    "    m8_v_pred = [(m8_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m8_v_acc = sum([p == y for p, y in m8_v_pred]) * 1. / len(m8_v_pred)\n",
    "    print \"model 8 validation accuracy (top_lim = %d) = %f\" % (top_lim, m8_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8 test accuracy = 0.759561\n"
     ]
    }
   ],
   "source": [
    "m8_t_pred = [(m8_predict(uid, aid, 9), y) for uid, aid, y in testing_set]\n",
    "m8_t_acc = sum([p == y for p, y in m8_t_pred]) * 1. / len(m8_t_pred)\n",
    "print \"model 8 test accuracy = %f\" % m8_t_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #10\n",
    "m9_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m9_predict(uid, aid, jac_thresh):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(u1s, u2s):\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        for uid2 in train['artists'][aid].user_listens:\n",
    "            u1s = set(train['users'][uid].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            u1s2 = set(train['users'][uid].tags.keys())\n",
    "            u2s2 = set(train['users'][uid2].tags.keys())\n",
    "            jac = (jaccard(u1s, u2s) + jaccard(u1s2, u2s2)) / 2.\n",
    "            if jac > jac_thresh:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 9 validation accuracy (jac_thresh = 0.000000) = 0.640472\n",
      "model 9 validation accuracy (jac_thresh = 0.050000) = 0.783592\n",
      "model 9 validation accuracy (jac_thresh = 0.100000) = 0.725698\n",
      "model 9 validation accuracy (jac_thresh = 0.150000) = 0.632080\n",
      "model 9 validation accuracy (jac_thresh = 0.200000) = 0.558478\n",
      "model 9 validation accuracy (jac_thresh = 0.250000) = 0.521228\n",
      "model 9 validation accuracy (jac_thresh = 0.300000) = 0.508527\n",
      "model 9 validation accuracy (jac_thresh = 0.350000) = 0.504712\n",
      "model 9 validation accuracy (jac_thresh = 0.400000) = 0.503411\n",
      "model 9 validation accuracy (jac_thresh = 0.450000) = 0.502872\n",
      "model 9 validation accuracy (jac_thresh = 0.500000) = 0.502513\n"
     ]
    }
   ],
   "source": [
    "# model 9 predictions\n",
    "for jac_thresh in np.arange(0, 0.55, 0.05):\n",
    "    m9_v_pred = [(m9_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m9_v_acc = sum([p == y for p, y in m9_v_pred]) * 1. / len(m9_v_pred)\n",
    "    print \"model 9 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m9_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 9 validation accuracy (jac_thresh = 0.000000) = 0.640472\n",
      "model 9 validation accuracy (jac_thresh = 0.010000) = 0.692487\n",
      "model 9 validation accuracy (jac_thresh = 0.020000) = 0.744188\n",
      "model 9 validation accuracy (jac_thresh = 0.030000) = 0.770712\n",
      "model 9 validation accuracy (jac_thresh = 0.040000) = 0.782336\n",
      "model 9 validation accuracy (jac_thresh = 0.050000) = 0.783592\n",
      "model 9 validation accuracy (jac_thresh = 0.060000) = 0.780585\n",
      "model 9 validation accuracy (jac_thresh = 0.070000) = 0.772013\n",
      "model 9 validation accuracy (jac_thresh = 0.080000) = 0.757652\n",
      "model 9 validation accuracy (jac_thresh = 0.090000) = 0.742707\n",
      "model 9 validation accuracy (jac_thresh = 0.100000) = 0.725698\n"
     ]
    }
   ],
   "source": [
    "# model 9 predictions\n",
    "for jac_thresh in np.arange(0, 0.11, 0.01):\n",
    "    m9_v_pred = [(m9_predict(uid, aid, jac_thresh), y) for uid, aid, y in validation_set]\n",
    "    m9_v_acc = sum([p == y for p, y in m9_v_pred]) * 1. / len(m9_v_pred)\n",
    "    print \"model 9 validation accuracy (jac_thresh = %f) = %f\" % (jac_thresh, m9_v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #10\n",
    "m10_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m10_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(u1s, u2s):\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        for uid2 in train['artists'][aid].user_listens:\n",
    "            u1s = set(train['users'][uid].artist_listens.keys())\n",
    "            u2s = set(train['users'][uid2].artist_listens.keys())\n",
    "            u1s2 = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid].tags.iteritems()], reverse = True)][:top_lim])\n",
    "            u2s2 = set([t for f, t in sorted([(f, t) for t, f in train['users'][uid2].tags.iteritems()], reverse = True)][:top_lim])\n",
    "            jac = (jaccard(u1s, u2s) + jaccard(u1s2, u2s2)) / 2.\n",
    "            if jac > 0.04:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 validation accuracy (top_lim = 17) = 0.781528\n",
      "model 10 validation accuracy (top_lim = 18) = 0.781079\n",
      "model 10 validation accuracy (top_lim = 19) = 0.781393\n",
      "model 10 validation accuracy (top_lim = 20) = 0.780540\n",
      "model 10 validation accuracy (top_lim = 21) = 0.780047\n",
      "model 10 validation accuracy (top_lim = 22) = 0.782246\n",
      "model 10 validation accuracy (top_lim = 23) = 0.781438\n",
      "model 10 validation accuracy (top_lim = 24) = 0.781214\n",
      "model 10 validation accuracy (top_lim = 25) = 0.780675\n",
      "model 10 validation accuracy (top_lim = 26) = 0.780406\n",
      "model 10 validation accuracy (top_lim = 27) = 0.780226\n",
      "model 10 validation accuracy (top_lim = 28) = 0.782021\n",
      "model 10 validation accuracy (top_lim = 29) = 0.782021\n"
     ]
    }
   ],
   "source": [
    "# model 10 predictions\n",
    "for top_lim in range(17, 30):\n",
    "    m10_v_pred = [(m10_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m10_v_acc = sum([p == y for p, y in m10_v_pred]) * 1. / len(m10_v_pred)\n",
    "    print \"model 10 validation accuracy (top_lim = %d) = %f\" % (top_lim, m10_v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #11\n",
    "m11_top_artists = set(a.aid for _, a in top_artists[:50])\n",
    "def m11_predict(uid, aid, top_lim):\n",
    "    # if we haven't seen the user before, just return whether the artist is in the top 50 artists\n",
    "    if uid not in train['users']:\n",
    "        return aid in m1_top_artists\n",
    "    \n",
    "    # if we have seen the user before, but not the artist, return whether this user listens to a variety of artists\n",
    "    # i.e. more than the average number of artists a user has listened to\n",
    "    elif aid not in train['artists']:\n",
    "        return len(train['users'][uid].artist_listens.keys()) > 30\n",
    "    \n",
    "    # if we've seen the user and the artist before, and this user has listened to this artist, return True\n",
    "    elif aid in train['users'][uid].artist_listens:\n",
    "        return True\n",
    "    \n",
    "    # if we've seen both the user and artist before, but have no prior listens recorded, return True if this user is\n",
    "    # similar to any of the users that listened to this artist\n",
    "    else:\n",
    "        def jaccard(uid1, uid2):\n",
    "            u1s = set([a for f, a in sorted([(f, a) for a, f in train['users'][uid].artist_listens.iteritems()], reverse = True)][:top_lim])\n",
    "            u2s = set([a for f, a in sorted([(f, a) for a, f in train['users'][uid2].artist_listens.iteritems()], reverse = True)][:top_lim])\n",
    "            if len(u1s | u2s) == 0: return 0\n",
    "            return len(u1s & u2s) * 1. / len(u1s | u2s)\n",
    "        return any(jaccard(uid, uid2) > 0.04 for uid2 in train['artists'][aid].user_listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 11 validation accuracy (top_lim = 15) = 0.800557\n",
      "model 11 validation accuracy (top_lim = 16) = 0.802800\n",
      "model 11 validation accuracy (top_lim = 17) = 0.804551\n",
      "model 11 validation accuracy (top_lim = 18) = 0.806481\n",
      "model 11 validation accuracy (top_lim = 19) = 0.808365\n",
      "model 11 validation accuracy (top_lim = 20) = 0.809667\n",
      "model 11 validation accuracy (top_lim = 21) = 0.810924\n",
      "model 11 validation accuracy (top_lim = 22) = 0.810071\n",
      "model 11 validation accuracy (top_lim = 23) = 0.810250\n",
      "model 11 validation accuracy (top_lim = 24) = 0.809577\n",
      "model 11 validation accuracy (top_lim = 25) = 0.808410\n"
     ]
    }
   ],
   "source": [
    "for top_lim in range(15, 26):\n",
    "    m11_v_pred = [(m11_predict(uid, aid, top_lim), y) for uid, aid, y in validation_set]\n",
    "    m11_v_acc = sum([p == y for p, y in m11_v_pred]) * 1. / len(m11_v_pred)\n",
    "    print \"model 11 validation accuracy (top_lim = %d) = %f\" % (top_lim, m11_v_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
